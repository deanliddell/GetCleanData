<html>
<head>
<style>
    body {
        font: normal 1.0em/1.3em serif;
        letter-spacing: 0.03em;
    }
    code {
        font-size: larger;
    }
    figcaption {
        font-size: smaller;
        text-align: center;
    }
    li {
        margin-bottom: 0.5em;
    }
    span.ul {
        display: inline-block;
        border-bottom: dashed thin;
        margin: 1.0em 0 1.0em 0;
    }
    a {
        color: blue;
        text-decoration: none;
    }
</style>
</head>
<body>
<h1 style="background-color:#EFEFEF;padding:1.0em 0;">Code Book</h1>

<h2>Data Set Information</h2>

<h3 style="font-weight:normal">UC Irvine Machine Learning Repository<br />Center for Machine
Learning and Intelligent Systems</h3>

<hr>

<p><figure style="float:right"><img src="samsung-galaxy-s-ii.jpg" height="300" width="165"
/><figcaption>Samsung Galaxy S II<br />Smartphone</figcaption></figure>The experiments have been
carried out with a group of 30 volunteers within an age bracket of 19 â€“ 48 years. Each person
performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING,
LAYING) wearing a smartphone (Samsung&reg; Galaxy S II) on the waist. Using its embedded
accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular
velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data
manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the
volunteers was selected for generating the training data and 30% the test data.</p>

<p><figure style="float:left"><img src="smartphone-wrist-arm-band.jpg" height="223" width="298"
/><figcaption>Smartphone Harness<br />Arm or Body Bands</figcaption></figure> The sensor
signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then
sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The
sensor acceleration signal, which has gravitational and body motion components, was separated
using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force
is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff
frequency was used. From each window, a vector of features was obtained by calculating variables
from the time and frequency domain.</p>

<p>A sample video of the experiment including an example of the 6 recorded activities with one
of the participants is available on YouTube&reg; as: <a
href="https://www.youtube.com/watch?v=XOEN9W05_4A" target="_blank">Activity Recognition
Experiment Using Smartphone Sensors</a>.</p>

<h2>Data Set Description</h2>

<ul><span class="ul">Each record recorded in the experiment provides:</span>
<li>Triaxial acceleration from the accelerometer (total acceleration) and the estimated body
acceleration.</li>
<li>Triaxial Angular velocity from the gyroscope.</li>
<li>A 561-feature vector with time and frequency domain variables.</li>
<li>Its activity label.</li>
<li>An identifier of the subject who carried out the experiment.</li>
</ul>

<ul><span class="ul">The dataset includes the following files:</span>
<li><code>README.txt</code></li>
<li><code>features_info.txt</code>: Shows information about the variables used on the feature
vector.</li>
<li><code>features.txt</code>: List of all features.</li>
<li><code>activity_labels.txt</code>: Links the class labels with their activity name.</li>
<li><code>train/X_train.txt</code>: Training set.</li>
<li><code>train/y_train.txt</code>: Training labels.</li>
<li><code>test/X_test.txt</code>: Test set.</li>
<li><code>test/y_test.txt</code>: Test labels.</li>
</ul>

<ul><span class="ul">The following files are available for the train and test data. Their
descriptions are equivalent.</span> 
<li><code>train/subject_train.txt</code>: Each row identifies the subject who performed the
activity for each window sample. Its range is from 1 to 30.</li>
<li><code>train/Inertial Signals/total_acc_x_train.txt</code>: The acceleration signal from the
smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element
vector. The same description applies for the <code>total_acc_x_train.txt</code> and
<code>total_acc_z_train.txt</code> files for the Y and Z axis.</li>
<li><code>train/Inertial Signals/body_acc_x_train.txt</code>: The body acceleration signal
obtained by subtracting the gravity from the total acceleration.</li>
<li><code>train/Inertial Signals/body_gyro_x_train.txt</code>: The angular velocity vector
measured by the gyroscope for each window sample. The units are radians/second.</li>
</ul>

<ul><span class="ul">Notes:</span> 
<li>Features are normalized and bounded within [-1,1].</li>
<li>Each feature vector is a row on the text file.</li>
<li>The units used for the accelerations (total and body) are 'g's (gravity of earth &rarr; 9.80665
m/seg<sup>2</sup>).</li>
<li>The gyroscope units are rad/seg.</li>
</ul>

<p>For more information about this dataset please contact:
<code>activityrecognition'@'smartlab.ws</code></p>

<h2>Data Transformation</h2>

</body>
</html>
